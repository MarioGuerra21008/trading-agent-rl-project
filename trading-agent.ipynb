{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8241dfb8",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <td style=\"width:20%; vertical-align:middle;\">\n",
    "      <img src=\"LogoUVG.png\" width=\"400\"/>\n",
    "    </td>\n",
    "    <td style=\"text-align:left; vertical-align:middle;\">\n",
    "      <h2 style=\"margin-bottom: 0;\">Universidad del Valle de Guatemala - UVG</h2>\n",
    "      <h3 style=\"margin-top: 0;\">Facultad de Ingeniería - Computación</h3>\n",
    "      <p style=\"font-size: 16px; margin-bottom: 0; margin-top: -20px\">\n",
    "        <strong>Curso:</strong> CC3104 - Aprendizaje por Refuerzo \n",
    "        <strong>Sección:</strong> 10\n",
    "      </p>\n",
    "      <p style=\"font-size: 16px; margin: 0;\"><strong>Agente de trading que aprenda a tomar decisiones de compra, venta o mantenimiento de un activo financiero dentro de un mercado simulado</strong></p>\n",
    "      <br>\n",
    "      <p style=\"font-size: 15px; margin: 0;\"><strong>Autores:</strong></p>\n",
    "      <ul style=\"margin-top: 5px; padding-left: 20px; font-size: 15px;\">\n",
    "        <li>Diego Alexander Hernández Silvestre - <strong>21270</strong></li>\n",
    "        <li>Linda Inés Jiménez Vides - <strong>21169</strong></li>\n",
    "        <li>Mario Antonio Guerra Morales - <strong>21008</strong></li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ebcbf5",
   "metadata": {},
   "source": [
    "### Instalación de dependencias e importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy pandas matplotlib jupyterlab\n",
    "#!pip install --index-url https://download.pytorch.org/whl/cpu torch\n",
    "#!pip install --index-url https://download.pytorch.org/whl/cu121 torch # cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d186cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías y módulos\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# PyTorch para Deep Q-Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dataclasses import dataclass\n",
    "from typing import Deque, Tuple, List\n",
    "\n",
    "# Reproducibilidad\n",
    "SEED = 2000\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Ajustes de gráficos\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "022c909b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hiperparámetros del entorno y de Deep Q-Network\n",
    "\n",
    "# Entorno\n",
    "N_STEPS = 4000 # longitud de pasos en entrenamiento\n",
    "TEST_STEPS = 1200 # longitud en test\n",
    "WINDOW = 30 # tamaño de la ventana de observación\n",
    "TRANS_COST = 0.001 # costo de transacción por cambiar de posición\n",
    "INIT_CASH = 1_000.0 # efectivo inicial\n",
    "UNIT_POSITION = 1 # tamaño unitario de posición\n",
    "ALLOW_SHORT = True # permitir posición -1 (venta en corto)\n",
    "VOL_SCALE = 0.20 # volatilidad anualizada para Gradient Boosting Models\n",
    "DRIFT = 0.05 # drift anualizado para GBM\n",
    "\n",
    "# DQN\n",
    "GAMMA = 0.99\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "REPLAY_SIZE = 50_000\n",
    "MIN_REPLAY = 2_000 # pasos mínimos antes de entrenar\n",
    "TARGET_SYNC = 1000 # frecuencia de sync a la target net\n",
    "EPS_START = 1.0\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY_STEPS = 30_000\n",
    "TRAIN_STEPS = 50_000 # total de pasos de entrenamiento\n",
    "DOUBLE_DQN = True # usar Double DQN\n",
    "\n",
    "# Evaluación\n",
    "RISK_FREE = 0.0 # se asume tasa libre de riesgo 0 para Sharpe simple\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72ba09",
   "metadata": {},
   "source": [
    "### Generación de precios para el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e69e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de precios y demás utilidades\n",
    "\n",
    "def geometric_brownian_motion(\n",
    "        # Genera una trayectoria GBM discreta:\n",
    "        # S_{t+1} = S_t * exp((mu - 0.5 sigma^2) dt + sigma * sqrt(dt) * Z_t)\n",
    "        # # Retorna arreglo de precios (longitud n_steps).\n",
    "        n_steps: int,\n",
    "        s0: float = 100.0,\n",
    "        mu: float = DRIFT,\n",
    "        sigma: float = VOL_SCALE,\n",
    "        dt: float = 1/252) -> np.ndarray:\n",
    "    \n",
    "    prices = np.zeros(n_steps, dtype=np.float64)\n",
    "    prices[0] = s0\n",
    "    for t in range(1, n_steps):\n",
    "        z = np.random.randn()\n",
    "        prices[t] = prices[t-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * math.sqrt(dt) * z)\n",
    "    return prices\n",
    "\n",
    "def to_log_returns(prices: np.ndarray) -> np.ndarray: # Retornos logarítmicos r_t = log(S_t / S_{t-1})\n",
    "    r = np.zeros_like(prices)\n",
    "    r[1:] = np.diff(np.log(prices))\n",
    "    return r\n",
    "\n",
    "def sharpe_ratio(returns: np.ndarray, risk_free: float = RISK_FREE, eps: float = 1e-9) -> float:\n",
    "    # Sharpe diario sobre retornos diarios (media - rf) / std.\n",
    "    if returns.std() < eps:\n",
    "        return 0.0\n",
    "    return float((returns.mean() - risk_free) / (returns.std() + eps)) * math.sqrt(252)\n",
    "\n",
    "def max_drawdown(equity: np.ndarray) -> float: # Máxima caída (drawdown) en porcentaje positivo\n",
    "    peaks = np.maximum.accumulate(equity)\n",
    "    drawdowns = 1.0 - (equity / np.maximum(peaks, 1e-9))\n",
    "    return float(drawdowns.max())\n",
    "\n",
    "def plot_equity(equity_dict: dict, title=\"Equity curves\"): # Gráfico para curvas de equidad\n",
    "    for label, eq in equity_dict.items():\n",
    "        plt.plot(eq, label=label)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Equity (value)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886577e1",
   "metadata": {},
   "source": [
    "### Entorno de trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122a1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entorno de trading uniactivo con acciones discretas {sell, hold, buy} -> posiciones {-1, 0, +1}.\n",
    "# Recompensa = Δ(valor portafolio) neto de costos al cambiar de posición.\n",
    "# Observación = [ventana de retornos recientes, posición_actual]\n",
    "\n",
    "class TradingEnv:\n",
    "    def __init__(self, prices: np.ndarray, window: int = WINDOW, trans_cost: float = TRANS_COST,\n",
    "                 init_cash: float = INIT_CASH, allow_short: bool = True):\n",
    "        self.prices = prices.astype(np.float64)\n",
    "        self.returns = to_log_returns(self.prices)\n",
    "        self.window = window\n",
    "        self.trans_cost = trans_cost\n",
    "        self.init_cash = init_cash\n",
    "        self.allow_short = allow_short\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.t = self.window  # primer índice válido para ventana\n",
    "        self.cash = float(self.init_cash)\n",
    "        self.position = 0     # -1, 0, +1\n",
    "        self.equity = [self.cash]\n",
    "        self.last_price = float(self.prices[self.t-1])\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        # obs = [retornos_window, posición_norm]\n",
    "        window_rets = self.returns[self.t - self.window : self.t]\n",
    "        pos_norm = np.array([self.position], dtype=np.float32)  # ya está en [-1,0,1]\n",
    "        obs = np.concatenate([window_rets.astype(np.float32), pos_norm], axis=0)\n",
    "        return obs\n",
    "\n",
    "    def step(self, action: int):\n",
    "        # action in {0,1,2} -> {sell(-1), hold(0), buy(+1)}.\n",
    "        # Cambiar de posición incurre en costo: trans_cost * precio * |delta_pos| * UNIT_POSITION\n",
    "        # Recompensa = Δequity (cambio en valor de portafolio) = pnl de la posición + costos (negativos)\n",
    "\n",
    "        assert action in (0, 1, 2)\n",
    "        desired_pos = {-1: 0, 0: 1, 1: 2}[self.position]  # mapeo solo para claridad\n",
    "        target_pos = {-1: 0, 0: 0, 1: 0}  # placeholder\n",
    "\n",
    "        target = {-1: 0, 0: 0, 1: 0} # ignora\n",
    "\n",
    "        if action == 0: # sell -> posición -1\n",
    "            new_pos = -1 if self.allow_short else 0\n",
    "        elif action == 1: # hold -> mantener\n",
    "            new_pos = self.position\n",
    "        else: # buy -> +1\n",
    "            new_pos = 1\n",
    "\n",
    "        price_t = float(self.prices[self.t])\n",
    "        price_tm1 = float(self.prices[self.t - 1])\n",
    "        ret_t = math.log(price_t / price_tm1 + 1e-12) # retorno log\n",
    "\n",
    "        # PnL por tener la posición previa en [t-1, t]\n",
    "        pnl = self.position * ret_t * self.cash  # aproximación: valoriza sobre cash\n",
    "        # Alternativa más fiel: trackear cantidad de activos; aquí simplificamos para claridad.\n",
    "\n",
    "        # Costo por cambiar de posición en caso de cambios.\n",
    "        delta_pos = abs(new_pos - self.position)\n",
    "        cost = delta_pos * self.trans_cost * price_t * UNIT_POSITION\n",
    "\n",
    "        # Actualizamos estado financiero\n",
    "        self.cash += pnl - cost\n",
    "        self.position = new_pos\n",
    "        self.equity.append(self.cash)\n",
    "\n",
    "        # Recompensa = delta equity paso a paso (pnl - cost)\n",
    "        reward = pnl - cost\n",
    "\n",
    "        self.t += 1\n",
    "        done = self.t >= len(self.prices)\n",
    "        obs = self._get_obs() if not done else None\n",
    "        info = {\"pnl\": pnl, \"cost\": cost, \"price\": price_t}\n",
    "        return obs, float(reward), bool(done), info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
